"""
Monthly Client Report Workflow
Auto-pulls Search Atlas + DataForSEO data + job history → narrative report
that justifies retainers and shows clients what's been done.

inputs keys: domain, service, location, report_month, notes
"""

import os
import asyncio
import anthropic
from typing import AsyncGenerator
from datetime import datetime, timezone

from utils.searchatlas import sa_call
from utils.dataforseo import (
    get_domain_rank_overview,
    get_domain_ranked_keywords,
    format_domain_ranked_keywords,
    build_location_name,
)
from utils.db import get_jobs_by_client

SYSTEM_PROMPT = """You are a client reporting strategist for ProofPilot, a results-driven digital marketing agency specializing in home service businesses.

Your job is to write monthly client reports that clearly communicate VALUE — not just data dumps. These reports justify the retainer and build long-term trust.

## Report principles
- Lead with wins and momentum — even small gains are wins
- Translate SEO data into business language (rankings → leads → revenue)
- Be specific: "You moved from position 23 to position 11 for 'panel upgrade Chandler AZ'" — not "rankings improved"
- Highlight deliverables completed this month (content, audits, GBP posts, etc.)
- Include a forward-looking section: what's planned next month and why
- Use the client's business context (service type, location, revenue) to frame everything
- If data shows negative trends, acknowledge them honestly and explain the plan to address them
- No fluff, no filler — every section should make the client feel their investment is working

## Format (strict)
Use clean markdown:

# Monthly SEO Report: [Client Name] — [Month Year]

## Executive Summary
[3-4 sentences: biggest win, overall trajectory, key metric highlight]

## Key Metrics This Month
[Table or bullet list of core KPIs: total keywords, estimated traffic, traffic value, position changes]

## Rankings Performance
[Top keyword movements, new rankings, position improvements]

## Work Completed This Month
[Deliverables from the job history — audits, content, GBP posts, etc.]

## SEO Health Overview
[Pillar scores, backlink status, technical health — from Search Atlas data]

## Next Month's Plan
[What's coming, why it matters, expected impact]

---

*Report generated by ProofPilot Agency Hub*

Do NOT write any preamble or explanation. Start directly with the H1 title."""


# ── Data gathering ────────────────────────────────────────────────────────────

async def _gather_sa_report_data(domain: str) -> dict[str, str]:
    """Fetch Search Atlas data for the monthly report."""

    async def safe_call(tool: str, op: str, params: dict, label: str) -> tuple[str, str]:
        try:
            result = await sa_call(tool, op, params)
            return label, result
        except Exception as e:
            return label, f"Data unavailable: {e}"

    tasks = [
        safe_call(
            "Site_Explorer_Organic_Tool", "get_organic_keywords",
            {"project_identifier": domain, "page_size": 25, "ordering": "-traffic"},
            "organic_keywords",
        ),
        safe_call(
            "Site_Explorer_Analysis_Tool", "get_position_distribution",
            {"identifier": domain},
            "position_distribution",
        ),
        safe_call(
            "Site_Explorer_Holistic_Audit_Tool", "get_holistic_seo_pillar_scores",
            {"domain": domain},
            "pillar_scores",
        ),
        safe_call(
            "Site_Explorer_Backlinks_Tool", "get_site_referring_domains",
            {"project_identifier": domain, "page_size": 10, "ordering": "-domain_rating"},
            "referring_domains",
        ),
    ]

    results = await asyncio.gather(*tasks)
    return dict(results)


async def _gather_dfs_report_data(
    domain: str, location_name: str,
) -> dict:
    """Fetch DataForSEO Labs data for the report."""
    dfs_login = os.environ.get("DATAFORSEO_LOGIN", "")
    dfs_pass = os.environ.get("DATAFORSEO_PASSWORD", "")
    if not dfs_login or not dfs_pass:
        return {}

    try:
        overview, ranked = await asyncio.gather(
            get_domain_rank_overview(domain, location_name),
            get_domain_ranked_keywords(domain, location_name, limit=25),
            return_exceptions=True,
        )

        result = {}
        if not isinstance(overview, Exception):
            result["overview"] = overview
        if not isinstance(ranked, Exception):
            result["ranked_keywords"] = ranked
        return result

    except Exception:
        return {}


# ── Main workflow ─────────────────────────────────────────────────────────────

async def run_monthly_report(
    client: anthropic.AsyncAnthropic,
    inputs: dict,
    strategy_context: str,
    client_name: str,
    client_id: int = 0,
) -> AsyncGenerator[str, None]:
    """
    Streams a monthly client report with real data.

    inputs keys:
        domain        e.g. "allthingzelectric.com"
        service       e.g. "electrician"
        location      e.g. "Chandler, AZ"
        report_month  e.g. "February 2026" (optional, defaults to current)
        notes         optional context
    """
    domain       = inputs.get("domain", "").strip()
    service      = inputs.get("service", "").strip()
    location     = inputs.get("location", "").strip()
    report_month = inputs.get("report_month", "").strip()
    notes        = inputs.get("notes", "").strip()

    if not report_month:
        report_month = datetime.now(timezone.utc).strftime("%B %Y")

    # ── Phase 1: Gather all data concurrently ──────────────────
    yield f"> Pulling SEO data for **{client_name}** ({domain})...\n\n"

    async def _empty_dict():
        return {}

    sa_task = _gather_sa_report_data(domain) if domain else _empty_dict()

    location_name = build_location_name(location) if location else ""
    dfs_task = _gather_dfs_report_data(domain, location_name) if (domain and location_name) else _empty_dict()

    # Fetch job history for this client
    yield f"> Loading deliverables completed this month...\n\n"

    sa_data, dfs_data, job_history = await asyncio.gather(
        sa_task, dfs_task,
        asyncio.to_thread(get_jobs_by_client, client_id),
        return_exceptions=True,
    )

    # Graceful fallbacks
    if isinstance(sa_data, Exception):
        sa_data = {}
    if isinstance(dfs_data, Exception):
        dfs_data = {}
    if isinstance(job_history, Exception):
        job_history = []

    # ── Phase 2: Build data context for Claude ─────────────────
    yield f"> Building report with real market data...\n\n"
    yield "---\n\n"

    context_sections = []

    # Search Atlas data
    if sa_data:
        if sa_data.get("organic_keywords") and "unavailable" not in sa_data["organic_keywords"].lower():
            context_sections.append(f"### Current Organic Keywords (Search Atlas)\n{sa_data['organic_keywords']}")
        if sa_data.get("position_distribution") and "unavailable" not in sa_data["position_distribution"].lower():
            context_sections.append(f"### Position Distribution\n{sa_data['position_distribution']}")
        if sa_data.get("pillar_scores") and "unavailable" not in sa_data["pillar_scores"].lower():
            context_sections.append(f"### SEO Pillar Scores\n{sa_data['pillar_scores']}")
        if sa_data.get("referring_domains") and "unavailable" not in sa_data["referring_domains"].lower():
            context_sections.append(f"### Referring Domains\n{sa_data['referring_domains']}")

    # DataForSEO data
    if dfs_data:
        overview = dfs_data.get("overview")
        if overview:
            context_sections.append(
                f"### Domain Overview (DataForSEO Labs)\n"
                f"- Total ranked keywords: {overview.get('keywords', 'N/A')}\n"
                f"- Estimated monthly traffic: {overview.get('etv', 'N/A')}\n"
                f"- Estimated traffic value: ${overview.get('etv_cost', 'N/A')}/mo\n"
            )
        ranked = dfs_data.get("ranked_keywords")
        if ranked:
            context_sections.append(
                f"### Top Ranked Keywords (DataForSEO Labs)\n{format_domain_ranked_keywords(ranked)}"
            )

    # Job history — deliverables completed
    if job_history:
        deliverables = []
        for job in job_history:
            created = job.get("created_at", "")[:10]
            title = job.get("workflow_title", "Unknown")
            approved = " (Approved)" if job.get("approved") else ""
            deliverables.append(f"- {created}: {title}{approved}")
        context_sections.append(f"### Deliverables Completed\n" + "\n".join(deliverables))
    else:
        context_sections.append("### Deliverables Completed\nNo jobs recorded for this client yet.")

    context_doc = "\n\n".join(context_sections) if context_sections else "No data available — report will be based on general recommendations."

    # ── Phase 3: Stream from Claude ────────────────────────────
    prompt_lines = [
        f"Write a Monthly SEO Report for **{client_name}**, a {service or 'home service business'} serving {location or 'their local market'}.",
        f"",
        f"**Report period:** {report_month}",
        f"**Domain:** {domain or 'Not specified'}",
        f"",
        f"## Real SEO Data (use this to build the report — cite specific numbers)",
        f"",
        context_doc,
    ]

    if strategy_context and strategy_context.strip():
        prompt_lines += [
            f"",
            f"## Strategy Context",
            f"{strategy_context.strip()}",
        ]

    if notes:
        prompt_lines += [
            f"",
            f"## Additional Notes",
            f"{notes}",
        ]

    prompt_lines += [
        f"",
        f"Write the complete monthly report now. Start directly with the H1 title. Reference specific data points from above — real numbers build trust.",
    ]

    user_prompt = "\n".join(prompt_lines)

    async with client.messages.stream(
        model="claude-opus-4-6",
        max_tokens=10000,
        thinking={"type": "adaptive"},
        system=SYSTEM_PROMPT,
        messages=[{"role": "user", "content": user_prompt}],
    ) as stream:
        async for text in stream.text_stream:
            yield text
